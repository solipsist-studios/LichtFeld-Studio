/* SPDX-FileCopyrightText: 2025 LichtFeld Studio Authors
 *
 * SPDX-License-Identifier: GPL-3.0-or-later */

#include "colmap.hpp"
#include "core/image_io.hpp"
#include "core/logger.hpp"
#include "core/path_utils.hpp"
#include "io/filesystem_utils.hpp"
#include <algorithm>
#include <cmath>
#include <cstring>
#include <exception>
#include <filesystem>
#include <fstream>
#include <memory>
#include <sstream>
#include <stdexcept>
#include <unordered_map>
#include <vector>

namespace lfs::io {

    // Import types from lfs::core for convenience
    using lfs::core::Camera;
    using lfs::core::DataType;
    using lfs::core::Device;
    using lfs::core::PointCloud;
    using lfs::core::Tensor;

    namespace fs = std::filesystem;

    // -----------------------------------------------------------------------------
    //  Quaternion to rotation matrix (torch-free)
    // -----------------------------------------------------------------------------
    inline Tensor qvec2rotmat(const std::vector<float>& q_raw) {
        if (q_raw.size() != 4) {
            LOG_ERROR("Quaternion must have 4 elements");
            throw std::runtime_error("Invalid quaternion size");
        }

        // Normalize quaternion
        float len = std::sqrt(q_raw[0] * q_raw[0] + q_raw[1] * q_raw[1] +
                              q_raw[2] * q_raw[2] + q_raw[3] * q_raw[3]);
        if (len < 1e-8f) {
            LOG_ERROR("Quaternion has zero length");
            throw std::runtime_error("Zero-length quaternion");
        }

        float w = q_raw[0] / len;
        float x = q_raw[1] / len;
        float y = q_raw[2] / len;
        float z = q_raw[3] / len;

        // Build rotation matrix [3, 3]
        std::vector<float> R_data = {
            1.0f - 2.0f * (y * y + z * z), 2.0f * (x * y - z * w), 2.0f * (x * z + y * w),
            2.0f * (x * y + z * w), 1.0f - 2.0f * (x * x + z * z), 2.0f * (y * z - x * w),
            2.0f * (x * z - y * w), 2.0f * (y * z + x * w), 1.0f - 2.0f * (x * x + y * y)};

        return Tensor::from_vector(R_data, {3, 3}, Device::CPU);
    }

    // -----------------------------------------------------------------------------
    //  Image data structure
    // -----------------------------------------------------------------------------
    struct ImageData {
        uint32_t image_id = 0;
        uint32_t camera_id = 0;
        std::string name;
        std::vector<float> qvec = {1.0f, 0.0f, 0.0f, 0.0f}; // [w, x, y, z]
        std::vector<float> tvec = {0.0f, 0.0f, 0.0f};
    };

    // -----------------------------------------------------------------------------
    //  Camera data structure (intermediate)
    // -----------------------------------------------------------------------------
    struct CameraDataIntermediate {
        uint32_t camera_id = 0;
        int model_id = 0;
        int width = 0;
        int height = 0;
        std::vector<float> params;
    };

    // -----------------------------------------------------------------------------
    //  POD read helpers
    // -----------------------------------------------------------------------------
    static inline uint64_t read_u64(const char*& p) {
        uint64_t v;
        std::memcpy(&v, p, 8);
        p += 8;
        return v;
    }
    static inline uint32_t read_u32(const char*& p) {
        uint32_t v;
        std::memcpy(&v, p, 4);
        p += 4;
        return v;
    }
    static inline int32_t read_i32(const char*& p) {
        int32_t v;
        std::memcpy(&v, p, 4);
        p += 4;
        return v;
    }
    static inline double read_f64(const char*& p) {
        double v;
        std::memcpy(&v, p, 8);
        p += 8;
        return v;
    }

    // -----------------------------------------------------------------------------
    //  COLMAP camera-model map
    // -----------------------------------------------------------------------------
    enum class CAMERA_MODEL {
        SIMPLE_PINHOLE = 0,
        PINHOLE = 1,
        SIMPLE_RADIAL = 2,
        RADIAL = 3,
        OPENCV = 4,
        OPENCV_FISHEYE = 5,
        FULL_OPENCV = 6,
        FOV = 7,
        SIMPLE_RADIAL_FISHEYE = 8,
        RADIAL_FISHEYE = 9,
        THIN_PRISM_FISHEYE = 10,
        UNDEFINED = 11
    };

    static const std::unordered_map<int, std::pair<CAMERA_MODEL, int32_t>> camera_model_ids = {
        {0, {CAMERA_MODEL::SIMPLE_PINHOLE, 3}},
        {1, {CAMERA_MODEL::PINHOLE, 4}},
        {2, {CAMERA_MODEL::SIMPLE_RADIAL, 4}},
        {3, {CAMERA_MODEL::RADIAL, 5}},
        {4, {CAMERA_MODEL::OPENCV, 8}},
        {5, {CAMERA_MODEL::OPENCV_FISHEYE, 8}},
        {6, {CAMERA_MODEL::FULL_OPENCV, 12}},
        {7, {CAMERA_MODEL::FOV, 5}},
        {8, {CAMERA_MODEL::SIMPLE_RADIAL_FISHEYE, 4}},
        {9, {CAMERA_MODEL::RADIAL_FISHEYE, 5}},
        {10, {CAMERA_MODEL::THIN_PRISM_FISHEYE, 12}},
        {11, {CAMERA_MODEL::UNDEFINED, -1}}};

    static const std::unordered_map<std::string, CAMERA_MODEL> camera_model_names = {
        {"SIMPLE_PINHOLE", CAMERA_MODEL::SIMPLE_PINHOLE},
        {"PINHOLE", CAMERA_MODEL::PINHOLE},
        {"SIMPLE_RADIAL", CAMERA_MODEL::SIMPLE_RADIAL},
        {"RADIAL", CAMERA_MODEL::RADIAL},
        {"OPENCV", CAMERA_MODEL::OPENCV},
        {"OPENCV_FISHEYE", CAMERA_MODEL::OPENCV_FISHEYE},
        {"FULL_OPENCV", CAMERA_MODEL::FULL_OPENCV},
        {"FOV", CAMERA_MODEL::FOV},
        {"SIMPLE_RADIAL_FISHEYE", CAMERA_MODEL::SIMPLE_RADIAL_FISHEYE},
        {"RADIAL_FISHEYE", CAMERA_MODEL::RADIAL_FISHEYE},
        {"THIN_PRISM_FISHEYE", CAMERA_MODEL::THIN_PRISM_FISHEYE}};

    // -----------------------------------------------------------------------------
    //  Binary-file loader
    // -----------------------------------------------------------------------------
    static std::unique_ptr<std::vector<char>>
    read_binary(const std::filesystem::path& p) {
        LOG_TRACE("Reading binary file: {}", lfs::core::path_to_utf8(p));
        std::ifstream f;
        if (!lfs::core::open_file_for_read(p, std::ios::binary | std::ios::ate, f)) {
            LOG_ERROR("Failed to open binary file: {}", lfs::core::path_to_utf8(p));
            throw std::runtime_error("Failed to open " + lfs::core::path_to_utf8(p));
        }

        auto sz = static_cast<std::streamsize>(f.tellg());
        auto buf = std::make_unique<std::vector<char>>(static_cast<size_t>(sz));

        f.seekg(0, std::ios::beg);
        f.read(buf->data(), sz);
        if (!f) {
            LOG_ERROR("Short read on binary file: {}", lfs::core::path_to_utf8(p));
            throw std::runtime_error("Short read on " + lfs::core::path_to_utf8(p));
        }
        LOG_TRACE("Read {} bytes from {}", sz, lfs::core::path_to_utf8(p));
        return buf;
    }

    // -----------------------------------------------------------------------------
    //  Helper to scale camera intrinsics
    // -----------------------------------------------------------------------------
    static void scale_camera_intrinsics(CAMERA_MODEL model, std::vector<float>& params, float factor) {
        switch (model) {
        case CAMERA_MODEL::SIMPLE_PINHOLE:
            params[0] /= factor; // f
            params[1] /= factor; // cx
            params[2] /= factor; // cy
            break;

        case CAMERA_MODEL::PINHOLE:
            params[0] /= factor; // fx
            params[1] /= factor; // fy
            params[2] /= factor; // cx
            params[3] /= factor; // cy
            break;

        case CAMERA_MODEL::SIMPLE_RADIAL:
        case CAMERA_MODEL::RADIAL:
            params[0] /= factor; // f
            params[1] /= factor; // cx
            params[2] /= factor; // cy
            break;

        case CAMERA_MODEL::OPENCV:
        case CAMERA_MODEL::OPENCV_FISHEYE:
        case CAMERA_MODEL::FULL_OPENCV:
            params[0] /= factor; // fx
            params[1] /= factor; // fy
            params[2] /= factor; // cx
            params[3] /= factor; // cy
            break;

        case CAMERA_MODEL::SIMPLE_RADIAL_FISHEYE:
        case CAMERA_MODEL::RADIAL_FISHEYE:
            params[0] /= factor; // f
            params[1] /= factor; // cx
            params[2] /= factor; // cy
            break;

        case CAMERA_MODEL::FOV:
            params[0] /= factor; // fx
            params[1] /= factor; // fy
            params[2] /= factor; // cx
            params[3] /= factor; // cy
            break;

        case CAMERA_MODEL::THIN_PRISM_FISHEYE:
            params[0] /= factor; // fx
            params[1] /= factor; // fy
            params[2] /= factor; // cx
            params[3] /= factor; // cy
            break;

        default:
            LOG_WARN("Unknown camera model for scaling");
            if (params.size() >= 4) {
                params[2] /= factor; // cx
                params[3] /= factor; // cy
            }
            break;
        }
    }

    // -----------------------------------------------------------------------------
    //  Helper to extract scale factor from folder name
    // -----------------------------------------------------------------------------
    static float extract_scale_from_folder(const std::string& folder_name) {
        size_t underscore_pos = folder_name.rfind('_');
        if (underscore_pos != std::string::npos) {
            std::string suffix = folder_name.substr(underscore_pos + 1);
            try {
                float factor = std::stof(suffix);
                if (factor > 0 && factor <= 16) {
                    LOG_DEBUG("Extracted scale factor {} from folder name", factor);
                    return factor;
                }
            } catch (...) {
            }
        }
        return 1.0f;
    }

    // -----------------------------------------------------------------------------
    //  images.bin
    // -----------------------------------------------------------------------------
    std::vector<ImageData> read_images_binary(const std::filesystem::path& file_path) {
        LOG_TIMER_TRACE("Read images.bin");
        auto buf_owner = read_binary(file_path);
        const char* cur = buf_owner->data();
        const char* end = cur + buf_owner->size();

        uint64_t n_images = read_u64(cur);
        LOG_DEBUG("Reading {} images from binary file", n_images);
        std::vector<ImageData> images;
        images.reserve(n_images);

        for (uint64_t i = 0; i < n_images; ++i) {
            ImageData img;
            img.image_id = read_u32(cur);

            // Read quaternion [w, x, y, z]
            for (int k = 0; k < 4; ++k) {
                img.qvec[k] = static_cast<float>(read_f64(cur));
            }

            // Read translation [x, y, z]
            for (int k = 0; k < 3; ++k) {
                img.tvec[k] = static_cast<float>(read_f64(cur));
            }

            img.camera_id = read_u32(cur);

            img.name.assign(cur);
            cur += img.name.size() + 1;

            uint64_t npts = read_u64(cur);
            cur += npts * (sizeof(double) * 2 + sizeof(uint64_t));

            images.push_back(std::move(img));
        }

        if (cur != end) {
            LOG_ERROR("images.bin has trailing bytes");
            throw std::runtime_error("images.bin: trailing bytes");
        }
        return images;
    }

    // -----------------------------------------------------------------------------
    //  cameras.bin
    // -----------------------------------------------------------------------------
    std::unordered_map<uint32_t, CameraDataIntermediate>
    read_cameras_binary(const std::filesystem::path& file_path, float scale_factor = 1.0f) {
        LOG_TIMER_TRACE("Read cameras.bin");
        auto buf_owner = read_binary(file_path);
        const char* cur = buf_owner->data();
        const char* end = cur + buf_owner->size();

        uint64_t n_cams = read_u64(cur);
        LOG_DEBUG("Reading {} cameras from binary file{}", n_cams,
                  scale_factor != 1.0f ? std::format(" with scale factor {}", scale_factor) : "");

        std::unordered_map<uint32_t, CameraDataIntermediate> cams;
        cams.reserve(n_cams);

        for (uint64_t i = 0; i < n_cams; ++i) {
            CameraDataIntermediate cam;
            cam.camera_id = read_u32(cur);
            cam.model_id = read_i32(cur);
            cam.width = static_cast<int>(read_u64(cur));
            cam.height = static_cast<int>(read_u64(cur));

            if (scale_factor != 1.0f) {
                cam.width = static_cast<int>(cam.width / scale_factor);
                cam.height = static_cast<int>(cam.height / scale_factor);
            }

            auto it = camera_model_ids.find(cam.model_id);
            if (it == camera_model_ids.end() || it->second.second < 0) {
                LOG_ERROR("Unsupported camera-model id: {}", cam.model_id);
                throw std::runtime_error("Unsupported camera-model id");
            }

            int32_t param_cnt = it->second.second;
            cam.params.resize(param_cnt);

            for (int j = 0; j < param_cnt; j++) {
                cam.params[j] = static_cast<float>(read_f64(cur));
            }

            if (scale_factor != 1.0f) {
                scale_camera_intrinsics(it->second.first, cam.params, scale_factor);
            }

            cams.emplace(cam.camera_id, std::move(cam));
        }

        if (cur != end) {
            LOG_ERROR("cameras.bin has trailing bytes");
            throw std::runtime_error("cameras.bin: trailing bytes");
        }
        return cams;
    }

    // -----------------------------------------------------------------------------
    //  points3D.bin
    // -----------------------------------------------------------------------------
    PointCloud read_point3D_binary(const std::filesystem::path& file_path) {
        LOG_TIMER_TRACE("Read points3D.bin");
        auto buf_owner = read_binary(file_path);
        const char* cur = buf_owner->data();
        const char* end = cur + buf_owner->size();

        uint64_t N = read_u64(cur);
        LOG_DEBUG("Reading {} 3D points from binary file", N);

        std::vector<float> positions(N * 3);
        std::vector<uint8_t> colors(N * 3);

        for (uint64_t i = 0; i < N; ++i) {
            cur += 8; // skip point ID

            positions[i * 3 + 0] = static_cast<float>(read_f64(cur));
            positions[i * 3 + 1] = static_cast<float>(read_f64(cur));
            positions[i * 3 + 2] = static_cast<float>(read_f64(cur));

            // Store colors as uint8 [0,255] to match old loader
            colors[i * 3 + 0] = static_cast<uint8_t>(*cur++);
            colors[i * 3 + 1] = static_cast<uint8_t>(*cur++);
            colors[i * 3 + 2] = static_cast<uint8_t>(*cur++);

            cur += 8;                                    // skip reprojection error
            cur += read_u64(cur) * sizeof(uint32_t) * 2; // skip track
        }

        if (cur != end) {
            LOG_ERROR("points3D.bin has trailing bytes");
            throw std::runtime_error("points3D.bin: trailing bytes");
        }

        Tensor means = Tensor::from_vector(positions, {N, 3}, Device::CUDA);
        Tensor colors_tensor = Tensor::from_blob(colors.data(), {N, 3}, Device::CPU, DataType::UInt8)
                                   .to(Device::CUDA)
                                   .contiguous();

        return PointCloud(std::move(means), std::move(colors_tensor));
    }

    // -----------------------------------------------------------------------------
    //  Text-file helpers
    // -----------------------------------------------------------------------------
    std::vector<std::string> read_text_file(const std::filesystem::path& file_path) {
        LOG_TRACE("Reading text file: {}", lfs::core::path_to_utf8(file_path));
        std::ifstream file;
        if (!lfs::core::open_file_for_read(file_path, file)) {
            LOG_ERROR("Failed to open text file: {}", lfs::core::path_to_utf8(file_path));
            throw std::runtime_error("Failed to open " + lfs::core::path_to_utf8(file_path));
        }

        std::vector<std::string> lines;
        std::string line;
        while (std::getline(file, line)) {
            if (line.starts_with("#"))
                continue;
            if (!line.empty() && line.back() == '\r')
                line.pop_back();
            // Skip empty lines
            if (line.empty())
                continue;
            lines.push_back(line);
        }

        if (lines.empty()) {
            LOG_ERROR("File is empty: {}", lfs::core::path_to_utf8(file_path));
            throw std::runtime_error("File is empty");
        }

        if (lines.back().empty())
            lines.pop_back();

        LOG_TRACE("Read {} lines from text file", lines.size());
        return lines;
    }

    std::vector<std::string> split_string(const std::string& s, char delimiter) {
        std::vector<std::string> tokens;
        size_t start = 0;
        size_t end = s.find(delimiter);

        while (end != std::string::npos) {
            tokens.push_back(s.substr(start, end - start));
            start = end + 1;
            end = s.find(delimiter, start);
        }
        tokens.push_back(s.substr(start));

        return tokens;
    }

    // -----------------------------------------------------------------------------
    //  images.txt
    // -----------------------------------------------------------------------------
    std::vector<ImageData> read_images_text(const std::filesystem::path& file_path) {
        LOG_TIMER_TRACE("Read images.txt");
        auto lines = read_text_file(file_path);

        std::vector<ImageData> images;
        images.reserve(lines.size());

        for (size_t line_idx = 0; line_idx < lines.size(); ++line_idx) {
            const auto& line = lines[line_idx];
            std::istringstream iss(line);

            ImageData img;
            if (!(iss >> img.image_id >> img.qvec[0] >> img.qvec[1] >> img.qvec[2] >> img.qvec[3] >> img.tvec[0] >> img.tvec[1] >> img.tvec[2] >> img.camera_id)) {
                continue;
            }

            iss >> std::ws;
            if (!std::getline(iss, img.name) || img.name.empty()) {
                continue;
            }

            auto dot_pos = img.name.rfind('.');
            if (dot_pos == std::string::npos || dot_pos == img.name.size() - 1) {
                continue;
            }
            bool has_extension = std::isalpha(static_cast<unsigned char>(img.name[dot_pos + 1]));
            if (!has_extension) {
                continue;
            }

            images.push_back(std::move(img));
        }

        if (images.empty()) {
            LOG_ERROR("No valid images found in {}", lfs::core::path_to_utf8(file_path));
            throw std::runtime_error("No valid images in images.txt");
        }

        LOG_DEBUG("Read {} images from text file", images.size());
        return images;
    }

    // -----------------------------------------------------------------------------
    //  cameras.txt
    // -----------------------------------------------------------------------------
    std::unordered_map<uint32_t, CameraDataIntermediate>
    read_cameras_text(const std::filesystem::path& file_path, float scale_factor = 1.0f) {
        LOG_TIMER_TRACE("Read cameras.txt");
        auto lines = read_text_file(file_path);

        LOG_DEBUG("Reading {} cameras from text file{}", lines.size(),
                  scale_factor != 1.0f ? std::format(" with scale factor {}", scale_factor) : "");

        std::unordered_map<uint32_t, CameraDataIntermediate> cams;

        for (const auto& line : lines) {
            const auto tokens = split_string(line, ' ');
            if (tokens.size() < 4) {
                LOG_ERROR("Invalid format in cameras.txt: {}", line);
                throw std::runtime_error("Invalid format in cameras.txt");
            }

            CameraDataIntermediate cam;
            cam.camera_id = std::stoul(tokens[0]);

            if (!camera_model_names.contains(tokens[1])) {
                LOG_ERROR("Unknown camera model: {}", tokens[1]);
                throw std::runtime_error("Unknown camera model");
            }

            cam.model_id = static_cast<int>(camera_model_names.at(tokens[1]));
            cam.width = std::stoi(tokens[2]);
            cam.height = std::stoi(tokens[3]);

            if (scale_factor != 1.0f) {
                cam.width = static_cast<int>(cam.width / scale_factor);
                cam.height = static_cast<int>(cam.height / scale_factor);
            }

            for (size_t j = 4; j < tokens.size(); ++j) {
                cam.params.push_back(std::stof(tokens[j]));
            }

            auto it = camera_model_ids.find(cam.model_id);
            if (it != camera_model_ids.end() && scale_factor != 1.0f) {
                scale_camera_intrinsics(it->second.first, cam.params, scale_factor);
            }

            cams.emplace(cam.camera_id, std::move(cam));
        }

        return cams;
    }

    // -----------------------------------------------------------------------------
    //  points3D.txt
    // -----------------------------------------------------------------------------
    PointCloud read_point3D_text(const std::filesystem::path& file_path) {
        LOG_TIMER_TRACE("Read points3D.txt");
        auto lines = read_text_file(file_path);
        uint64_t N = lines.size();
        LOG_DEBUG("Reading {} 3D points from text file", N);

        std::vector<float> positions(N * 3);
        std::vector<uint8_t> colors(N * 3);

        for (uint64_t i = 0; i < N; ++i) {
            const auto& line = lines[i];
            const auto tokens = split_string(line, ' ');

            if (tokens.size() < 8) {
                LOG_ERROR("Invalid format in points3D.txt: {}", line);
                throw std::runtime_error("Invalid format in points3D.txt");
            }

            positions[i * 3 + 0] = std::stof(tokens[1]);
            positions[i * 3 + 1] = std::stof(tokens[2]);
            positions[i * 3 + 2] = std::stof(tokens[3]);

            // Store colors as uint8 [0,255] to match old loader
            colors[i * 3 + 0] = static_cast<uint8_t>(std::stoi(tokens[4]));
            colors[i * 3 + 1] = static_cast<uint8_t>(std::stoi(tokens[5]));
            colors[i * 3 + 2] = static_cast<uint8_t>(std::stoi(tokens[6]));
        }

        Tensor means = Tensor::from_vector(positions, {N, 3}, Device::CUDA);
        Tensor colors_tensor = Tensor::from_blob(colors.data(), {N, 3}, Device::CPU, DataType::UInt8)
                                   .to(Device::CUDA)
                                   .contiguous();

        return PointCloud(std::move(means), std::move(colors_tensor));
    }

    // -----------------------------------------------------------------------------
    //  Assemble cameras with dimension verification
    // -----------------------------------------------------------------------------
    namespace {
        constexpr std::array MASK_FOLDERS = {"masks", "mask", "segmentation"};
        constexpr std::array MASK_EXTENSIONS = {".png", ".jpg", ".jpeg", ".PNG", ".JPG", ".JPEG", ".mask.png"};
    } // namespace

    // Searches for mask file matching image_name in mask folders.
    // Priority: exact match, stem+ext (e.g., img.png), full+ext (e.g., img.jpg.png)
    static std::filesystem::path find_mask_path(const std::filesystem::path& base_path,
                                                const std::string& image_name) {
        const std::filesystem::path img_path = lfs::core::utf8_to_path(image_name);
        const std::filesystem::path stem_path = img_path.parent_path() / img_path.stem();

        for (const auto& folder : MASK_FOLDERS) {
            const std::filesystem::path mask_dir = base_path / folder;
            if (!std::filesystem::exists(mask_dir))
                continue;

            if (const auto exact = mask_dir / img_path; std::filesystem::exists(exact))
                return exact;

            for (const auto& ext : MASK_EXTENSIONS) {
                auto path = mask_dir / stem_path;
                path += ext;
                if (std::filesystem::exists(path))
                    return path;
            }

            for (const auto& ext : MASK_EXTENSIONS) {
                auto path = mask_dir / img_path;
                path += ext;
                if (std::filesystem::exists(path))
                    return path;
            }
        }
        return {};
    }

    Result<std::tuple<std::vector<std::shared_ptr<Camera>>, Tensor>>
    assemble_colmap_cameras(const std::filesystem::path& base_path,
                            const std::unordered_map<uint32_t, CameraDataIntermediate>& cam_map,
                            const std::vector<ImageData>& images,
                            const std::string& images_folder) {

        LOG_TIMER_TRACE("Assemble COLMAP cameras");

        std::filesystem::path images_path = base_path / images_folder;

        if (!std::filesystem::exists(images_path)) {
            return make_error(ErrorCode::PATH_NOT_FOUND,
                              "Images folder does not exist", images_path);
        }

        std::vector<std::shared_ptr<Camera>> cameras;
        cameras.reserve(images.size());

        // Accumulate camera positions for scene center
        std::vector<float> camera_positions;
        camera_positions.reserve(images.size() * 3);

        for (size_t i = 0; i < images.size(); ++i) {
            const ImageData& img = images[i];

            auto it = cam_map.find(img.camera_id);
            if (it == cam_map.end()) {
                return make_error(ErrorCode::CORRUPTED_DATA,
                                  std::format("Camera ID {} not found for image '{}'", img.camera_id, img.name),
                                  images_path / img.name);
            }

            const auto& cam_data = it->second;

            // Convert quaternion to rotation matrix
            Tensor R = qvec2rotmat(img.qvec);

            // Create translation tensor
            Tensor T = Tensor::from_vector(img.tvec, {3}, Device::CPU);

            // Calculate camera position: -R^T * T
            auto R_cpu = R.cpu();
            auto T_cpu = T.cpu();

            float RT[9];
            for (int r = 0; r < 3; ++r) {
                for (int c = 0; c < 3; ++c) {
                    RT[r * 3 + c] = R_cpu.ptr<float>()[c * 3 + r]; // Transpose
                }
            }

            float cam_pos[3] = {0, 0, 0};
            for (int r = 0; r < 3; ++r) {
                for (int c = 0; c < 3; ++c) {
                    cam_pos[r] -= RT[r * 3 + c] * T_cpu.ptr<float>()[c];
                }
            }

            camera_positions.push_back(cam_pos[0]);
            camera_positions.push_back(cam_pos[1]);
            camera_positions.push_back(cam_pos[2]);

            // Extract camera parameters based on model
            auto model_it = camera_model_ids.find(cam_data.model_id);
            if (model_it == camera_model_ids.end()) {
                return make_error(ErrorCode::UNSUPPORTED_FORMAT,
                                  std::format("Invalid camera model ID {} for image '{}'", cam_data.model_id, img.name),
                                  images_path / img.name);
            }

            CAMERA_MODEL model = model_it->second.first;
            const auto& params = cam_data.params;

            float focal_x = 0, focal_y = 0, center_x = 0, center_y = 0;
            Tensor radial_dist, tangential_dist;
            lfs::core::CameraModelType camera_model_type = lfs::core::CameraModelType::PINHOLE;

            switch (model) {
            case CAMERA_MODEL::SIMPLE_PINHOLE:
                focal_x = focal_y = params[0];
                center_x = params[1];
                center_y = params[2];
                radial_dist = Tensor::empty({0}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                break;

            case CAMERA_MODEL::PINHOLE:
                focal_x = params[0];
                focal_y = params[1];
                center_x = params[2];
                center_y = params[3];
                radial_dist = Tensor::empty({0}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                break;

            case CAMERA_MODEL::SIMPLE_RADIAL:
                focal_x = focal_y = params[0];
                center_x = params[1];
                center_y = params[2];
                // k1 should be zero for COLMAP's SIMPLE_RADIAL to match a pinhole model
                if (params[3] != 0.0f) {
                    LOG_WARN("Camera uses SIMPLE_RADIAL model with non-zero k1 distortion ({})", params[3]);
                    radial_dist = Tensor::from_vector({params[3]}, {1}, Device::CPU);
                } else {
                    radial_dist = Tensor::empty({0}, Device::CPU);
                }
                tangential_dist = Tensor::empty({0}, Device::CPU);
                camera_model_type = lfs::core::CameraModelType::PINHOLE;
                break;

            case CAMERA_MODEL::RADIAL:
                focal_x = focal_y = params[0];
                center_x = params[1];
                center_y = params[2];
                radial_dist = Tensor::from_vector({params[3], params[4]}, {2}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                break;

            case CAMERA_MODEL::OPENCV:
                focal_x = params[0];
                focal_y = params[1];
                center_x = params[2];
                center_y = params[3];
                radial_dist = Tensor::from_vector({params[4], params[5]}, {2}, Device::CPU);
                tangential_dist = Tensor::from_vector({params[6], params[7]}, {2}, Device::CPU);
                break;

            case CAMERA_MODEL::FULL_OPENCV:
                focal_x = params[0];
                focal_y = params[1];
                center_x = params[2];
                center_y = params[3];
                radial_dist = Tensor::from_vector({params[4], params[5], params[8], params[9], params[10], params[11]}, {6}, Device::CPU);
                tangential_dist = Tensor::from_vector({params[6], params[7]}, {2}, Device::CPU);
                break;

            case CAMERA_MODEL::OPENCV_FISHEYE:
                focal_x = params[0];
                focal_y = params[1];
                center_x = params[2];
                center_y = params[3];
                radial_dist = Tensor::from_vector({params[4], params[5], params[6], params[7]}, {4}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                camera_model_type = lfs::core::CameraModelType::FISHEYE;
                break;

            case CAMERA_MODEL::RADIAL_FISHEYE:
                focal_x = focal_y = params[0];
                center_x = params[1];
                center_y = params[2];
                radial_dist = Tensor::from_vector({params[3], params[4]}, {2}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                camera_model_type = lfs::core::CameraModelType::FISHEYE;
                break;

            case CAMERA_MODEL::SIMPLE_RADIAL_FISHEYE:
                focal_x = focal_y = params[0];
                center_x = params[1];
                center_y = params[2];
                radial_dist = Tensor::from_vector({params[3]}, {1}, Device::CPU);
                tangential_dist = Tensor::empty({0}, Device::CPU);
                camera_model_type = lfs::core::CameraModelType::FISHEYE;
                break;

            case CAMERA_MODEL::THIN_PRISM_FISHEYE:
                // fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, sx1, sy1
                focal_x = params[0];
                focal_y = params[1];
                center_x = params[2];
                center_y = params[3];
                radial_dist = Tensor::from_vector({params[4], params[5], params[8], params[9]}, {4}, Device::CPU);       // k1,k2,k3,k4
                tangential_dist = Tensor::from_vector({params[6], params[7], params[10], params[11]}, {4}, Device::CPU); // p1,p2,sx1,sy1
                camera_model_type = lfs::core::CameraModelType::THIN_PRISM_FISHEYE;
                break;

            case CAMERA_MODEL::FOV:
                return make_error(ErrorCode::UNSUPPORTED_FORMAT,
                                  std::format("FOV camera model not supported for image '{}'", img.name),
                                  images_path / img.name);

            default:
                return make_error(ErrorCode::UNSUPPORTED_FORMAT,
                                  std::format("Unsupported camera model for image '{}'", img.name),
                                  images_path / img.name);
            }

            std::filesystem::path mask_path = find_mask_path(base_path, img.name);

            // Validate mask dimensions match image dimensions
            if (!mask_path.empty()) {
                auto [img_w, img_h, img_c] = lfs::core::get_image_info(images_path / img.name);
                auto [mask_w, mask_h, mask_c] = lfs::core::get_image_info(mask_path);
                if (img_w != mask_w || img_h != mask_h) {
                    return make_error(ErrorCode::MASK_SIZE_MISMATCH,
                                      std::format("Mask '{}' is {}x{} but image '{}' is {}x{}",
                                                  lfs::core::path_to_utf8(mask_path.filename()), mask_w, mask_h,
                                                  img.name, img_w, img_h),
                                      mask_path);
                }
            }

            // Create Camera
            auto camera = std::make_shared<Camera>(
                R,
                T,
                focal_x, focal_y,
                center_x, center_y,
                radial_dist,
                tangential_dist,
                camera_model_type,
                img.name,
                images_path / img.name,
                mask_path,
                cam_data.width,
                cam_data.height,
                static_cast<int>(i),
                static_cast<int>(img.camera_id));

            cameras.push_back(std::move(camera));
        }

        // Compute scene center as mean of camera positions
        Tensor scene_center_tensor = Tensor::from_vector(camera_positions, {images.size(), 3}, Device::CPU);
        Tensor scene_center = scene_center_tensor.mean({0}, false);

        LOG_INFO("Training with {} images", cameras.size());

        return std::make_tuple(std::move(cameras), scene_center);
    }

    // -----------------------------------------------------------------------------
    //  Public API
    // -----------------------------------------------------------------------------

    static fs::path get_sparse_file_path(const fs::path& base, const std::string& filename) {
        auto search_paths = get_colmap_search_paths(base);
        auto found = find_file_in_paths(search_paths, filename);

        if (!found.empty()) {
            LOG_TRACE("Found sparse file at: {}", lfs::core::path_to_utf8(found));
            return found;
        }

        std::string error_msg = std::format("Cannot find '{}' in any location", filename);
        LOG_ERROR("{}", error_msg);
        throw std::runtime_error(error_msg);
    }

    PointCloud read_colmap_point_cloud(const std::filesystem::path& filepath) {
        LOG_TIMER_TRACE("Read COLMAP point cloud");
        fs::path points3d_file = get_sparse_file_path(filepath, "points3D.bin");
        return read_point3D_binary(points3d_file);
    }

    Result<std::tuple<std::vector<std::shared_ptr<Camera>>, Tensor>>
    read_colmap_cameras_and_images(const std::filesystem::path& base,
                                   const std::string& images_folder) {

        LOG_TIMER_TRACE("Read COLMAP cameras and images");

        const float scale_factor = extract_scale_from_folder(images_folder);

        fs::path cams_file = get_sparse_file_path(base, "cameras.bin");
        fs::path images_file = get_sparse_file_path(base, "images.bin");

        auto cam_map = read_cameras_binary(cams_file, scale_factor);
        auto images = read_images_binary(images_file);

        LOG_INFO("Read {} cameras and {} images from COLMAP", cam_map.size(), images.size());

        return assemble_colmap_cameras(base, cam_map, images, images_folder);
    }

    PointCloud read_colmap_point_cloud_text(const std::filesystem::path& filepath) {
        LOG_TIMER_TRACE("Read COLMAP point cloud (text)");
        fs::path points3d_file = get_sparse_file_path(filepath, "points3D.txt");
        return read_point3D_text(points3d_file);
    }

    Result<std::tuple<std::vector<std::shared_ptr<Camera>>, Tensor>>
    read_colmap_cameras_and_images_text(const std::filesystem::path& base,
                                        const std::string& images_folder) {

        LOG_TIMER_TRACE("Read COLMAP cameras and images (text)");

        const float scale_factor = extract_scale_from_folder(images_folder);

        fs::path cams_file = get_sparse_file_path(base, "cameras.txt");
        fs::path images_file = get_sparse_file_path(base, "images.txt");

        auto cam_map = read_cameras_text(cams_file, scale_factor);
        auto images = read_images_text(images_file);

        LOG_INFO("Read {} cameras and {} images from COLMAP text files", cam_map.size(), images.size());

        return assemble_colmap_cameras(base, cam_map, images, images_folder);
    }

} // namespace lfs::io